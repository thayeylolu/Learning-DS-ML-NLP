import os
import random
import sys
import spacy

import scispacy
import spacy
import numpy as np
import pandas as pd


import matplotlib.pyplot as plt

import seaborn as sns
from ipywidgets import interactive

from scipy.cluster.hierarchy import dendrogram, fcluster, linkage
from sklearn import cluster, datasets, metrics
from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans
from sklearn.datasets import make_blobs
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import euclidean_distances
from sklearn.preprocessing import StandardScaler

nlp = en_core_sci_sm.load()
plt.rcParams["font.size"] = 16
# plt.style.use("seaborn")
get_ipython().run_line_magic("matplotlib", " inline")
pd.set_option("display.max_colwidth", 0)





nlp_cr = en_ner_craft_md.load()
nlp_bc = en_ner_bc5cdr_md.load()
nlp_bi = en_ner_bionlp13cg_md.load()
nlp_jn = en_ner_jnlpba_md.load()


df_train = pd.read_csv('../data/Train.csv')
df_test = pd.read_csv('../data/Test.csv')
df_sub = pd.read_csv('../data/Sample Submission.csv')


df_train.head()





# - work with the transcription first
# - use regex to get all the `CAPTALIZE WORD:`
# - copy all the words (grp) that appear between two captialized words 
# the grp of words should be assigned as value for the first occuring captialized word


doc = nlp(df_train.transcription[0])


for word in doc.ents:
    print(word.text ,  " | ", word.label_)


df_test.head()



