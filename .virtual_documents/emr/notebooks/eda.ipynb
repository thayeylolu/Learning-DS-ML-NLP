import os
import random
import sys
import spacy

import scispacy
import spacy
import numpy as np
import pandas as pd

#sys.path.append("code/.")
import matplotlib.pyplot as plt
#import mglearn
import seaborn as sns
from ipywidgets import interactive
#from plotting_functions import *
from scipy.cluster.hierarchy import dendrogram, fcluster, linkage
from sklearn import cluster, datasets, metrics
from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans
from sklearn.datasets import make_blobs
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import euclidean_distances
from sklearn.preprocessing import StandardScaler
#from support_functions import *
#from yellowbrick.cluster import SilhouetteVisualizer
nlp = spacy.load('en_core_web_sm')
plt.rcParams["font.size"] = 16
# plt.style.use("seaborn")
get_ipython().run_line_magic("matplotlib", " inline")
pd.set_option("display.max_colwidth", 0)


df_train = pd.read_csv('../data/Train.csv')
df_test = pd.read_csv('../data/Test.csv')
df_sub = pd.read_csv('../data/Sample Submission.csv')


df_train.head()





# - work with the transcription first
# - use regex to get all the `CAPTALIZE WORD:`
# - copy all the words (grp) that appear between two captialized words 
# the grp of words should be assigned as value for the first occuring captialized word


doc = nlp(df_train.transcription[0])


for word in doc.ents:
    print(word.text ,  " | ", word.label_)



